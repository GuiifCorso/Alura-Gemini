{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOR9kt0Hp00icBV/WV9QGqf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GuiifCorso/Alura-Gemini/blob/main/AI'Eye.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IajTCSb2H64C"
      },
      "outputs": [],
      "source": [
        "!pip install playsound --upgrade\n",
        "!pip install pillow\n",
        "!pip install gtts\n",
        "!pip install google.generativeai\n",
        "!pip install googletrans==4.0.0-rc1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from googletrans import Translator\n",
        "import os\n",
        "\n",
        "#Coletando a língua-mãe do usuário para tornar o \"aplicativo\" mais acessível\n",
        "language = os.environ.get(\"LANG\")\n",
        "\n",
        "lang_ab = language.split('.')[0]\n",
        "#Como a biblioteca \"os\" retorna a língua como en_US.UTF-8, precisa-se separar somente a língua, que é o que estou fazendo abaixo:\n",
        "lang = lang_ab[:2]\n",
        "#Mensagem base de início\n",
        "base_message = \"Qual site você estará acessando? \"\n",
        "\n",
        "\n",
        "#Definição do tradutor de texto para a língua no computador do usuário\n",
        "def translate_text(text, target_language='pt'):\n",
        "  translator = Translator()\n",
        "  translated_text = translator.translate(text, dest=target_language)\n",
        "  return translated_text.text\n",
        "\n",
        "#Nova mensagem base traduzida\n",
        "new_base_message = translate_text(base_message, lang)\n",
        "print(new_base_message)"
      ],
      "metadata": {
        "id": "Ua7GR0GG3liI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba370737-890b-48f2-af2e-4da18ffbecf6",
        "collapsed": true
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "À quel site allez-vous accéder?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import SupportsRound\n",
        "from gtts import gTTS\n",
        "from IPython.display import Audio\n",
        "from IPython.core.display import display\n",
        "\n",
        "#Aqui estarei criando um áudio, na língua-mãe do usuário, com o comando para o primeiro passo da utilização do software: Perguntar o site\n",
        "def audio_maker(text, lang, name):\n",
        "  tts = gTTS(text=text, lang=lang)\n",
        "  tts.save(f\"{name}.wav\")\n",
        "\n",
        "\n",
        "audio_maker(new_base_message, lang, f\"acess-{lang}\")\n",
        "\n",
        "def audio_play(audio):\n",
        "  display(Audio(audio, autoplay=True))\n",
        "\n",
        "\n",
        "#OBS: Estou aguardando a biblioteca playsound resolver algum problema que ela está tendo, pois não consigo reproduzir áudios. Se o problema continuar não estarei colocando a função de áudio :("
      ],
      "metadata": {
        "id": "dY6L0M6efFLP"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ast import Suite\n",
        "from IPython.display import Audio\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import time\n",
        "\n",
        "#Perguntando qual site o usuário gostaria de acessar\n",
        "audio_play(f\"acess-{lang}.wav\")\n",
        "time.sleep(5)\n",
        "print(new_base_message)\n",
        "site = input()\n",
        "\n",
        "api_key = userdata.get(\"SECRET_KEY\")\n",
        "genai.configure(api_key=api_key)\n",
        "\n",
        "# Set up the model\n",
        "generation_config = {\n",
        "  \"temperature\": 1,\n",
        "  \"top_p\": 0.95,\n",
        "  \"top_k\": 0,\n",
        "  \"max_output_tokens\": 8192,\n",
        "}\n",
        "\n",
        "safety_settings = [\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "  },\n",
        "]\n",
        "\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-pro-latest\",\n",
        "                              generation_config=generation_config,\n",
        "                              safety_settings=safety_settings)\n",
        "\n",
        "prompt_parts = [\n",
        "  \"input: globo\",\n",
        "  \"output: https://g1.globo.com\",\n",
        "  \"input: youtube\",\n",
        "  \"output: https://youtube.com\",\n",
        "  \"input: github\",\n",
        "  \"output: https://github.com\",\n",
        "  \"input: yt\",\n",
        "  \"output: https://youtube.com\",\n",
        "  \"input: whatsapp\",\n",
        "  \"output: https://whatsapp.com\",\n",
        "  \"input: alura\",\n",
        "  \"output: https://alura.com\",\n",
        "  \"input: udemy\",\n",
        "  \"output: https://udemy.com\",\n",
        "  \"input: times\",\n",
        "  \"output: https://nytimes.com\",\n",
        "  f\"input: {site}\",\n",
        "  \"output: \",\n",
        "]\n",
        "\n",
        "response = model.generate_content(prompt_parts)\n",
        "print(response.text)\n",
        "\n",
        "#A IA que construí acima, recebe o nome do site que o usuário quer acessar e transforma o valor em um link para que possa ser buscado no código seguinte\n",
        "url = response.text\n",
        "url = url.strip()"
      ],
      "metadata": {
        "id": "r1dCQh4n5Qzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests as r\n",
        "from bs4 import BeautifulSoup as bs\n",
        "import os\n",
        "\n",
        "\n",
        "#Utilizando a biblioteca requests e beautiful soup para entrar na página que o usuário quer\n",
        "response = r.get(url)\n",
        "soup = bs(response.content, \"html.parser\")\n",
        "\n",
        "image_list = []\n",
        "\n",
        "i = 0\n",
        "for image in image_list:\n",
        "  i += 1\n",
        "  os.remove(f\"/content/image{i}.jpg\")\n",
        "\n",
        "#Utilizando o beautifulsoup para encontrar todos os elementos \"img\" da página\n",
        "images = soup.find_all(\"img\", attrs={\"src\": True})\n",
        "\n",
        "index = 0\n",
        "\n",
        "#Para cada imagem encontrada, repetir o código abaixo:\n",
        "for image in images:\n",
        "    index += 1\n",
        "    #Aqui coleto o URL \"cru\" da imagem, que não consegue ser lido pela IA\n",
        "    image_raw_url = image[\"src\"]\n",
        "    #Aqui meio que \"abro\" o URL e acesso seus dados\n",
        "    if \"https\" in image_raw_url:\n",
        "      image_url = r.get(image_raw_url, stream=True)\n",
        "    else:\n",
        "      pass\n",
        "    #Atribuo à variável \"image\" o .content do URL, o que me dá os dados da imagem\n",
        "    image = image_url.content\n",
        "    #Com os dados da imagem, agora posso abrí-la em um arquivo, que chamarei de imagem[x], onde x é o número da imagem\n",
        "    with open(f\"image{index}.jpg\", \"wb\") as f:\n",
        "        f.write(image)\n",
        "    image_list.append(image_url)\n",
        "\n",
        "index = 0"
      ],
      "metadata": {
        "id": "BfwpL9o4WpOk"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import hashlib\n",
        "import google.generativeai as genai\n",
        "\n",
        "\n",
        "genai.configure(api_key=api_key)\n",
        "\n",
        "#Iniciando o modelo responsável pela descrição das imagens\n",
        "generation_config = {\n",
        "  \"temperature\": 1,\n",
        "  \"top_p\": 0.95,\n",
        "  \"top_k\": 0,\n",
        "  \"max_output_tokens\": 8192,\n",
        "}\n",
        "\n",
        "safety_settings = [\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "  },\n",
        "]\n",
        "\n",
        "system_instruction = \"Seja direto e curto, não enrole demais. Foque nos detalhes e na descrição do que estiver sendo pedido.\\nVocê atuará como um descritor de imagens para deficientes visuais, então deve analisar a imagem e descrevê-la em pouco menos de 300 palavras com o maior grau de entendimento.\"\n",
        "\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-pro-latest\",\n",
        "                              generation_config=generation_config,\n",
        "                              system_instruction=system_instruction,\n",
        "                              safety_settings=safety_settings)\n",
        "\n",
        "convo = model.start_chat(history=[\n",
        "])\n"
      ],
      "metadata": {
        "id": "99-_xQcSs51e"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import hashlib\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import time\n",
        "\n",
        "#Mensagem de continuação\n",
        "follow_message = \"Deseja continuar? Y para sim, N para não\"\n",
        "translated_follow_message = translate_text(follow_message, lang)\n",
        "audio_maker(translated_follow_message, lang, f\"follow-{lang}\")\n",
        "\n",
        "\n",
        "#Mensagem de erro\n",
        "error_message = \"Erro. Digite uma tecla válida\"\n",
        "translated_error_message = translate_text(error_message, lang)\n",
        "audio_maker(translated_error_message, lang, f\"error-{lang}\")\n",
        "\n",
        "#Mensagem de despedida\n",
        "bye_message = \"Muito obrigado! Até a próxima...\"\n",
        "translated_bye_message = translate_text(bye_message, lang)\n",
        "audio_maker(translated_bye_message, lang, f\"bye-{lang}\")\n",
        "\n",
        "#Para cada imagem encontrada, novamente, mas agora em uma lista, para deixá-las armazenadas\n",
        "for image in image_list:\n",
        "  loop = True\n",
        "  index += 1\n",
        "\n",
        "  path = f\"/content/image{index}.jpg\"\n",
        "\n",
        "  prompt = [genai.upload_file(path), f\"Descreva esta imagem na língua {language}:\"]\n",
        "  #A IA irá descrever cada imagem de acordo com o loop e a posição das imagens com base nas imagens .jpg criadas\n",
        "  convo.send_message(prompt)\n",
        "  print(convo.last.text)\n",
        "\n",
        "  #Criação e play dos áudios da descrição\n",
        "  audio_maker(convo.last.text, lang, f\"desc-{index}\")\n",
        "  audio_play(f\"desc-{index}.wav\")\n",
        "\n",
        "  print(\"-\"*50)\n",
        "\n",
        "  time.sleep(60)\n",
        "\n",
        "  #Opção de seguir ou continuar a descrever\n",
        "  audio_play(f\"follow-{lang}.wav\")\n",
        "  time.sleep(5)\n",
        "  print(translated_follow_message)\n",
        "\n",
        "\n",
        "  while loop:\n",
        "    follow = input().lower()\n",
        "    if follow == \"y\":\n",
        "      #Caso queira continuar\n",
        "      print(\"-\"*50)\n",
        "      loop = False\n",
        "      continue\n",
        "    elif follow == \"n\":\n",
        "      break\n",
        "    else:\n",
        "      #Caso dê erro:\n",
        "      audio_play(f\"error-{lang}.wav\")\n",
        "      print(translated_error_message)\n",
        "      continue\n",
        "  if follow == \"n\":\n",
        "    #Caso não queira mais continuar\n",
        "    audio_play(f\"bye-{lang}.wav\")\n",
        "    print(translated_bye_message)\n",
        "    break\n"
      ],
      "metadata": {
        "id": "kTROxHA_xEHp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}